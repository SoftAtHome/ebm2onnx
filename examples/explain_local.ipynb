{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for onnx conversion and inference\n",
    "import onnx\n",
    "import ebm2onnx\n",
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-killing",
   "metadata": {},
   "source": [
    "# Train a classfication model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('titanic_train.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "feature_columns = ['Age', 'Fare', 'Pclass', 'Embarked']\n",
    "label_column = \"Survived\"\n",
    "\n",
    "y = df[[label_column]]\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "x = df[feature_columns]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_enc)\n",
    "ebm = ExplainableBoostingClassifier(\n",
    "    interactions=2,\n",
    "    feature_types=['continuous', 'continuous', 'continuous', 'nominal']\n",
    ")\n",
    "ebm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the model to onnx\n",
    "onnx_model = ebm2onnx.to_onnx(\n",
    "    model=ebm,\n",
    "    explain=True,  # Generate a dedicated output for local explanations\n",
    "    dtype=ebm2onnx.get_dtype_from_pandas(x_train),\n",
    "    name=\"ebm\",\n",
    ")\n",
    "\n",
    "_, filename = tempfile.mkstemp()\n",
    "onnx.save_model(onnx_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set with ONNX-Runtime\n",
    "sess = rt.InferenceSession(filename)\n",
    "onnx_pred = sess.run(None, {\n",
    "    'Age': x_test['Age'].values,\n",
    "    'Fare': x_test['Fare'].values,\n",
    "    'Pclass': x_test['Pclass'].values,\n",
    "    'Embarked': x_test['Embarked'].values,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-arrest",
   "metadata": {},
   "source": [
    "# Local explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_onnx_local_explanation(predictions, sample_to_explain):\n",
    "    scores = predictions[1]    \n",
    "    scores = scores[sample_to_explain][:,0]\n",
    "    abs_scores = np.abs(scores)\n",
    "    sorted_indices = np.argsort(abs_scores)\n",
    "    scores = scores[sorted_indices]\n",
    "    \n",
    "    colors = [s > 0 for s in scores]\n",
    "\n",
    "    fig = px.bar(  \n",
    "        scores,\n",
    "        color=colors,\n",
    "        orientation='h',\n",
    "        color_discrete_map={\n",
    "            True: '#FF7F0E',\n",
    "            False: '#1F77B4',\n",
    "        },\n",
    "        text=[ebm.term_names_[i] for i in sorted_indices],\n",
    "        height=300,\n",
    "    )\n",
    "\n",
    "    fig.update(layout_showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, we plot the local explanations as provided by interpretml\n",
    "ebm_local = ebm.explain_local(x_test, y_test)\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ONNX predictions contain also the local explanation\n",
    "# We can display the same plots.\n",
    "\n",
    "show_onnx_local_explanation(onnx_pred, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
